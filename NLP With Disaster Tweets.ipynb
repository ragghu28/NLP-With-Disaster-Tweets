{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T11:07:07.689297Z","iopub.execute_input":"2021-09-06T11:07:07.689960Z","iopub.status.idle":"2021-09-06T11:07:07.705879Z","shell.execute_reply.started":"2021-09-06T11:07:07.689820Z","shell.execute_reply":"2021-09-06T11:07:07.704594Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hi All, It's my first notebook submission. Apology if the explaination is not clear.\nDo let me know your feedback in the commments**. ","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:07:29.647812Z","iopub.execute_input":"2021-09-06T11:07:29.648203Z","iopub.status.idle":"2021-09-06T11:07:29.860942Z","shell.execute_reply.started":"2021-09-06T11:07:29.648171Z","shell.execute_reply":"2021-09-06T11:07:29.859861Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:09:08.894430Z","iopub.execute_input":"2021-09-06T11:09:08.894821Z","iopub.status.idle":"2021-09-06T11:09:08.907947Z","shell.execute_reply.started":"2021-09-06T11:09:08.894791Z","shell.execute_reply":"2021-09-06T11:09:08.907028Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         id  target\n0         0       0\n1         2       0\n2         3       0\n3         9       0\n4        11       0\n...     ...     ...\n3258  10861       0\n3259  10865       0\n3260  10868       0\n3261  10874       0\n3262  10875       0\n\n[3263 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Import all the required Libraries like TF and Tranformers. \n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import AutoTokenizer, TFAutoModelForSequenceClassification, TFAutoModel\n\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter \n\nimport numpy as np \nfrom tqdm import tqdm\nimport pandas as pd \nimport os\nimport warnings\nimport re\n\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"WANDB_API_KEY\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:09:23.935145Z","iopub.execute_input":"2021-09-06T11:09:23.935579Z","iopub.status.idle":"2021-09-06T11:09:33.920216Z","shell.execute_reply.started":"2021-09-06T11:09:23.935543Z","shell.execute_reply":"2021-09-06T11:09:33.918931Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Just a basic syntax for TPU. \nYou can just copy - paste won't dwell into the details for the params \\. Just start the Accelarator as TPU.","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\nstrategy = tf.distribute.TPUStrategy(tpu)\nprint('Number of replicas:', strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:09:55.791962Z","iopub.execute_input":"2021-09-06T11:09:55.792375Z","iopub.status.idle":"2021-09-06T11:10:01.502166Z","shell.execute_reply.started":"2021-09-06T11:09:55.792341Z","shell.execute_reply":"2021-09-06T11:10:01.501356Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Number of replicas: 8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If We were going to do this by using GPUs we don't worry tensorflow will automatically take care of utilizing the GPU for the kaggle notebook. Just make sure to start the Accelarator as GPU.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE= 16 * strategy.num_replicas_in_sync","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:10:21.431852Z","iopub.execute_input":"2021-09-06T11:10:21.432281Z","iopub.status.idle":"2021-09-06T11:10:21.436814Z","shell.execute_reply.started":"2021-09-06T11:10:21.432244Z","shell.execute_reply":"2021-09-06T11:10:21.435509Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Just some basic ETL so see any missing or corrupt data \nThings we should definately take care of:-\n* Corrupt data anywhere - NaN\n* Check for unique labels of the data.\n* Any lables out of range of [0,1]\n* Outliers - This given a text data would be difficult to do so.\n\n","metadata":{}},{"cell_type":"code","source":"print(\"Data Head\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:13:27.341786Z","iopub.execute_input":"2021-09-06T11:13:27.342189Z","iopub.status.idle":"2021-09-06T11:13:27.356118Z","shell.execute_reply.started":"2021-09-06T11:13:27.342157Z","shell.execute_reply":"2021-09-06T11:13:27.354822Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Data Head\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Sentence IDs\")\ntrain_data['text'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:13:16.992054Z","iopub.execute_input":"2021-09-06T11:13:16.992433Z","iopub.status.idle":"2021-09-06T11:13:17.006073Z","shell.execute_reply.started":"2021-09-06T11:13:16.992402Z","shell.execute_reply":"2021-09-06T11:13:17.005248Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Sentence IDs\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"7503"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Null data: \")\ntrain_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:13:03.711562Z","iopub.execute_input":"2021-09-06T11:13:03.711978Z","iopub.status.idle":"2021-09-06T11:13:03.726202Z","shell.execute_reply.started":"2021-09-06T11:13:03.711941Z","shell.execute_reply":"2021-09-06T11:13:03.724902Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Null data: \n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"id             0\nkeyword       61\nlocation    2533\ntext           0\ntarget         0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"print(\"No of Unique Labels\")\ntrain_data.target.nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:12:52.894908Z","iopub.execute_input":"2021-09-06T11:12:52.895295Z","iopub.status.idle":"2021-09-06T11:12:52.904600Z","shell.execute_reply.started":"2021-09-06T11:12:52.895264Z","shell.execute_reply":"2021-09-06T11:12:52.903566Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"No of Unique Labels\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Label counts Info \")\ntrain_data.groupby('target').size().reset_index(name='counts')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:12:39.341245Z","iopub.execute_input":"2021-09-06T11:12:39.341621Z","iopub.status.idle":"2021-09-06T11:12:39.355853Z","shell.execute_reply.started":"2021-09-06T11:12:39.341589Z","shell.execute_reply":"2021-09-06T11:12:39.354782Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Label counts Info \n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"   target  counts\n0       0    4342\n1       1    3271","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3271</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"wrong_labels = train_data.groupby(['text']).nunique().sort_values(by='target', ascending=False)\nwrong_labels","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:13:46.332947Z","iopub.execute_input":"2021-09-06T11:13:46.333359Z","iopub.status.idle":"2021-09-06T11:13:46.387894Z","shell.execute_reply.started":"2021-09-06T11:13:46.333325Z","shell.execute_reply":"2021-09-06T11:13:46.386836Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                                    id  keyword  location  \\\ntext                                                                        \nlike for the music video I want some real actio...   2        2         1   \nHellfire! We donÛªt even want to think about i...   2        1         1   \nThe Prophet (peace be upon him) said 'Save your...   6        1         1   \nIn #islam saving a person is equal in reward to...   2        1         2   \nTo fight bioterrorism sir.                           4        1         0   \n...                                                 ..      ...       ...   \nBack from Seattle Tacoma and Portland. Whirlwin...   1        1         1   \nBaby elephant dies just days after surviving ma...   1        1         1   \nBUT I will be uploading these videos ASAP so yo...   1        1         1   \nBREAKING: Terror Attack On\\nPolice Post #Udhampur    1        1         1   \nåÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent...   1        1         1   \n\n                                                    target  \ntext                                                        \nlike for the music video I want some real actio...       2  \nHellfire! We donÛªt even want to think about i...       2  \nThe Prophet (peace be upon him) said 'Save your...       2  \nIn #islam saving a person is equal in reward to...       2  \nTo fight bioterrorism sir.                               2  \n...                                                    ...  \nBack from Seattle Tacoma and Portland. Whirlwin...       1  \nBaby elephant dies just days after surviving ma...       1  \nBUT I will be uploading these videos ASAP so yo...       1  \nBREAKING: Terror Attack On\\nPolice Post #Udhampur        1  \nåÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent...       1  \n\n[7503 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>text</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it #islam!</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'</th>\n      <td>6</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>To fight bioterrorism sir.</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>Back from Seattle Tacoma and Portland. Whirlwind! http://t.co/qwHINBni8e</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>Baby elephant dies just days after surviving massacre of his family http://t.co/qzCUT7bVKT</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>BUT I will be uploading these videos ASAP so you guys get to see the new weapon types in action!</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>BREAKING: Terror Attack On\\nPolice Post #Udhampur</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Tent Collapse Story: Correction: Tent Collapse story åÈ http://t.co/fDJUYvZMrv @wizkidayo</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7503 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see target more than 1 for few cases","metadata":{}},{"cell_type":"code","source":"wrong_labels = wrong_labels[wrong_labels['target'] > 1]['target']\nwr_label_list = wrong_labels.index.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:14:37.022593Z","iopub.execute_input":"2021-09-06T11:14:37.023016Z","iopub.status.idle":"2021-09-06T11:14:37.054519Z","shell.execute_reply.started":"2021-09-06T11:14:37.022964Z","shell.execute_reply":"2021-09-06T11:14:37.053290Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Here either you can re-label them manually or else just **Remove the wr_labels example**.\nI am removing as this re labelling is tedious man.","metadata":{}},{"cell_type":"code","source":"train_data = train_data[~train_data['text'].isin(wr_label_list)]","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:14:47.932886Z","iopub.execute_input":"2021-09-06T11:14:47.933292Z","iopub.status.idle":"2021-09-06T11:14:47.942150Z","shell.execute_reply.started":"2021-09-06T11:14:47.933260Z","shell.execute_reply":"2021-09-06T11:14:47.941050Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"**More 30% of location is NULL**","metadata":{}},{"cell_type":"markdown","source":"**But still keyword has low amount of corrupt data (Can be amputated).**","metadata":{}},{"cell_type":"markdown","source":"Lets look into our Test Data now","metadata":{}},{"cell_type":"code","source":"print(\"Data Head\")\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:15:16.292792Z","iopub.execute_input":"2021-09-06T11:15:16.293190Z","iopub.status.idle":"2021-09-06T11:15:16.309815Z","shell.execute_reply.started":"2021-09-06T11:15:16.293159Z","shell.execute_reply":"2021-09-06T11:15:16.308540Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Data Head\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text\n0   0     NaN      NaN                 Just happened a terrible car crash\n1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Null data: \")\ntest_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:15:28.340695Z","iopub.execute_input":"2021-09-06T11:15:28.341246Z","iopub.status.idle":"2021-09-06T11:15:28.355798Z","shell.execute_reply.started":"2021-09-06T11:15:28.341209Z","shell.execute_reply":"2021-09-06T11:15:28.354428Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Null data: \n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"id             0\nkeyword       26\nlocation    1105\ntext           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Sentence IDs\")\ntest_data['text'].nunique()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:15:37.093826Z","iopub.execute_input":"2021-09-06T11:15:37.094348Z","iopub.status.idle":"2021-09-06T11:15:37.103576Z","shell.execute_reply.started":"2021-09-06T11:15:37.094312Z","shell.execute_reply":"2021-09-06T11:15:37.102844Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Sentence IDs\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"3243"},"metadata":{}}]},{"cell_type":"markdown","source":"# A bit of Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"**As we can see Again a lot of location is NULL. Lets drop it.**  ","metadata":{}},{"cell_type":"code","source":"train_data.drop('location', axis=1, inplace=True)\ntest_data.drop('location', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:16:07.897137Z","iopub.execute_input":"2021-09-06T11:16:07.897541Z","iopub.status.idle":"2021-09-06T11:16:07.906367Z","shell.execute_reply.started":"2021-09-06T11:16:07.897507Z","shell.execute_reply":"2021-09-06T11:16:07.905176Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"First let clean the NaN tokens and then we will add this keyword after our tweets . **Do not worry Attention will take care for last token.** ","metadata":{}},{"cell_type":"code","source":"train_data['keyword'].fillna('', inplace=True)\ntest_data['keyword'].fillna('', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:16:36.497905Z","iopub.execute_input":"2021-09-06T11:16:36.498289Z","iopub.status.idle":"2021-09-06T11:16:36.507811Z","shell.execute_reply.started":"2021-09-06T11:16:36.498259Z","shell.execute_reply":"2021-09-06T11:16:36.506829Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Lets quickly glance our keyword column once. ","metadata":{}},{"cell_type":"code","source":"Counter(train_data.keyword.apply(lambda x: len(x.split())))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:16:49.411927Z","iopub.execute_input":"2021-09-06T11:16:49.412511Z","iopub.status.idle":"2021-09-06T11:16:49.427613Z","shell.execute_reply.started":"2021-09-06T11:16:49.412475Z","shell.execute_reply":"2021-09-06T11:16:49.426385Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"Counter({0: 61, 1: 7497})"},"metadata":{}}]},{"cell_type":"code","source":"counter = Counter(train_data['keyword'].to_list())\ncounter.most_common()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:16:59.777914Z","iopub.execute_input":"2021-09-06T11:16:59.778339Z","iopub.status.idle":"2021-09-06T11:16:59.800836Z","shell.execute_reply.started":"2021-09-06T11:16:59.778303Z","shell.execute_reply":"2021-09-06T11:16:59.799419Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[('', 61),\n ('fatalities', 45),\n ('armageddon', 42),\n ('deluge', 42),\n ('body%20bags', 41),\n ('damage', 41),\n ('harm', 41),\n ('collided', 40),\n ('evacuate', 40),\n ('fear', 40),\n ('outbreak', 40),\n ('siren', 40),\n ('twister', 40),\n ('windstorm', 40),\n ('collision', 39),\n ('derailment', 39),\n ('earthquake', 39),\n ('explosion', 39),\n ('famine', 39),\n ('flames', 39),\n ('sinkhole', 39),\n ('sunk', 39),\n ('weapon', 39),\n ('weapons', 39),\n ('whirlwind', 39),\n ('wreckage', 39),\n ('wrecked', 39),\n ('ambulance', 38),\n ('blaze', 38),\n ('bombed', 38),\n ('deaths', 38),\n ('derailed', 38),\n ('drowned', 38),\n ('explode', 38),\n ('fatal', 38),\n ('fire', 38),\n ('flooding', 38),\n ('hurricane', 38),\n ('oil%20spill', 38),\n ('thunder', 38),\n ('typhoon', 38),\n ('upheaval', 38),\n ('bioterror', 37),\n ('blizzard', 37),\n ('crush', 37),\n ('curfew', 37),\n ('debris', 37),\n ('destroy', 37),\n ('emergency', 37),\n ('fatality', 37),\n ('hostages', 37),\n ('mudslide', 37),\n ('pandemonium', 37),\n ('panic', 37),\n ('police', 37),\n ('quarantined', 37),\n ('ruin', 37),\n ('sandstorm', 37),\n ('sinking', 37),\n ('wounded', 37),\n ('wreck', 37),\n ('ablaze', 36),\n ('attack', 36),\n ('catastrophe', 36),\n ('cliff%20fall', 36),\n ('danger', 36),\n ('death', 36),\n ('desolation', 36),\n ('detonate', 36),\n ('devastation', 36),\n ('dust%20storm', 36),\n ('evacuated', 36),\n ('evacuation', 36),\n ('massacre', 36),\n ('nuclear%20reactor', 36),\n ('screaming', 36),\n ('tragedy', 36),\n ('accident', 35),\n ('airplane%20accident', 35),\n ('attacked', 35),\n ('bleeding', 35),\n ('blood', 35),\n ('bloody', 35),\n ('bridge%20collapse', 35),\n ('casualties', 35),\n ('collapsed', 35),\n ('demolition', 35),\n ('derail', 35),\n ('disaster', 35),\n ('drought', 35),\n ('emergency%20plan', 35),\n ('flood', 35),\n ('hail', 35),\n ('injured', 35),\n ('injury', 35),\n ('inundated', 35),\n ('razed', 35),\n ('rescued', 35),\n ('rescuers', 35),\n ('rioting', 35),\n ('screams', 35),\n ('storm', 35),\n ('structural%20failure', 35),\n ('suicide%20bomb', 35),\n ('tornado', 35),\n ('traumatised', 35),\n ('aftershock', 34),\n ('annihilated', 34),\n ('army', 34),\n ('arsonist', 34),\n ('blazing', 34),\n ('bomb', 34),\n ('burning', 34),\n ('burning%20buildings', 34),\n ('casualty', 34),\n ('collapse', 34),\n ('collide', 34),\n ('crashed', 34),\n ('demolish', 34),\n ('destruction', 34),\n ('drowning', 34),\n ('electrocuted', 34),\n ('flattened', 34),\n ('hazard', 34),\n ('heat%20wave', 34),\n ('lava', 34),\n ('loud%20bang', 34),\n ('military', 34),\n ('natural%20disaster', 34),\n ('nuclear%20disaster', 34),\n ('quarantine', 34),\n ('rainstorm', 34),\n ('refugees', 34),\n ('riot', 34),\n ('screamed', 34),\n ('smoke', 34),\n ('tsunami', 34),\n ('blew%20up', 33),\n ('blown%20up', 33),\n ('body%20bag', 33),\n ('body%20bagging', 33),\n ('buildings%20on%20fire', 33),\n ('burned', 33),\n ('chemical%20emergency', 33),\n ('crash', 33),\n ('emergency%20services', 33),\n ('exploded', 33),\n ('fire%20truck', 33),\n ('floods', 33),\n ('hijack', 33),\n ('hijacker', 33),\n ('injuries', 33),\n ('landslide', 33),\n ('lightning', 33),\n ('mass%20murder', 33),\n ('meltdown', 33),\n ('panicking', 33),\n ('stretcher', 33),\n ('suicide%20bombing', 33),\n ('survived', 33),\n ('thunderstorm', 33),\n ('trouble', 33),\n ('violent%20storm', 33),\n ('wildfire', 33),\n ('wounds', 33),\n ('apocalypse', 32),\n ('arson', 32),\n ('blight', 32),\n ('buildings%20burning', 32),\n ('cyclone', 32),\n ('destroyed', 32),\n ('detonation', 32),\n ('displaced', 32),\n ('drown', 32),\n ('electrocute', 32),\n ('eyewitness', 32),\n ('forest%20fires', 32),\n ('hailstorm', 32),\n ('hijacking', 32),\n ('mass%20murderer', 32),\n ('survive', 32),\n ('terrorism', 32),\n ('trapped', 32),\n ('crushed', 31),\n ('devastated', 31),\n ('hostage', 31),\n ('obliterate', 31),\n ('obliterated', 31),\n ('suicide%20bomber', 31),\n ('terrorist', 31),\n ('trauma', 31),\n ('wild%20fires', 31),\n ('avalanche', 30),\n ('catastrophic', 30),\n ('dead', 30),\n ('engulfed', 30),\n ('hazardous', 30),\n ('mayhem', 30),\n ('survivors', 30),\n ('annihilation', 29),\n ('bombing', 29),\n ('desolate', 29),\n ('first%20responders', 29),\n ('obliteration', 29),\n ('seismic', 29),\n ('sirens', 29),\n ('snowstorm', 29),\n ('demolished', 28),\n ('rubble', 28),\n ('deluged', 27),\n ('volcano', 27),\n ('battle', 26),\n ('bioterrorism', 26),\n ('bush%20fires', 25),\n ('hellfire', 25),\n ('war%20zone', 24),\n ('rescue', 22),\n ('forest%20fire', 19),\n ('epicentre', 12),\n ('threat', 11),\n ('inundation', 10),\n ('radiation%20emergency', 9)]"},"metadata":{}}]},{"cell_type":"markdown","source":"Lets once check out training and test dataset","metadata":{}},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:17:54.779223Z","iopub.execute_input":"2021-09-06T11:17:54.779735Z","iopub.status.idle":"2021-09-06T11:17:54.797319Z","shell.execute_reply.started":"2021-09-06T11:17:54.779700Z","shell.execute_reply":"2021-09-06T11:17:54.796533Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"         id keyword                                               text  target\n0         1          Our Deeds are the Reason of this #earthquake M...       1\n1         4                     Forest fire near La Ronge Sask. Canada       1\n2         5          All residents asked to 'shelter in place' are ...       1\n3         6          13,000 people receive #wildfires evacuation or...       1\n4         7          Just got sent this photo from Ruby #Alaska as ...       1\n...     ...     ...                                                ...     ...\n7608  10869          Two giant cranes holding a bridge collapse int...       1\n7609  10870          @aria_ahrary @TheTawniest The out of control w...       1\n7610  10871          M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1\n7611  10872          Police investigating after an e-bike collided ...       1\n7612  10873          The Latest: More Homes Razed by Northern Calif...       1\n\n[7558 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td></td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td></td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td></td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td></td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td></td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td></td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td></td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td></td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td></td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td></td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7558 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"As we can all are single word in keyword. Even the double words are url encoded as single words. \nLets decode the url words.","metadata":{}},{"cell_type":"code","source":"from urllib.parse import unquote\n\ntrain_data['keyword'] = train_data.keyword.apply(lambda x: unquote(x))\ntest_data['keyword'] = test_data.keyword.apply(lambda x: unquote(x))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:18:33.732147Z","iopub.execute_input":"2021-09-06T11:18:33.732687Z","iopub.status.idle":"2021-09-06T11:18:33.744765Z","shell.execute_reply.started":"2021-09-06T11:18:33.732644Z","shell.execute_reply":"2021-09-06T11:18:33.743821Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"counter = Counter(train_data['keyword'].to_list())\ncounter.most_common()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:18:37.413798Z","iopub.execute_input":"2021-09-06T11:18:37.414169Z","iopub.status.idle":"2021-09-06T11:18:37.433809Z","shell.execute_reply.started":"2021-09-06T11:18:37.414132Z","shell.execute_reply":"2021-09-06T11:18:37.433053Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[('', 61),\n ('fatalities', 45),\n ('armageddon', 42),\n ('deluge', 42),\n ('body bags', 41),\n ('damage', 41),\n ('harm', 41),\n ('collided', 40),\n ('evacuate', 40),\n ('fear', 40),\n ('outbreak', 40),\n ('siren', 40),\n ('twister', 40),\n ('windstorm', 40),\n ('collision', 39),\n ('derailment', 39),\n ('earthquake', 39),\n ('explosion', 39),\n ('famine', 39),\n ('flames', 39),\n ('sinkhole', 39),\n ('sunk', 39),\n ('weapon', 39),\n ('weapons', 39),\n ('whirlwind', 39),\n ('wreckage', 39),\n ('wrecked', 39),\n ('ambulance', 38),\n ('blaze', 38),\n ('bombed', 38),\n ('deaths', 38),\n ('derailed', 38),\n ('drowned', 38),\n ('explode', 38),\n ('fatal', 38),\n ('fire', 38),\n ('flooding', 38),\n ('hurricane', 38),\n ('oil spill', 38),\n ('thunder', 38),\n ('typhoon', 38),\n ('upheaval', 38),\n ('bioterror', 37),\n ('blizzard', 37),\n ('crush', 37),\n ('curfew', 37),\n ('debris', 37),\n ('destroy', 37),\n ('emergency', 37),\n ('fatality', 37),\n ('hostages', 37),\n ('mudslide', 37),\n ('pandemonium', 37),\n ('panic', 37),\n ('police', 37),\n ('quarantined', 37),\n ('ruin', 37),\n ('sandstorm', 37),\n ('sinking', 37),\n ('wounded', 37),\n ('wreck', 37),\n ('ablaze', 36),\n ('attack', 36),\n ('catastrophe', 36),\n ('cliff fall', 36),\n ('danger', 36),\n ('death', 36),\n ('desolation', 36),\n ('detonate', 36),\n ('devastation', 36),\n ('dust storm', 36),\n ('evacuated', 36),\n ('evacuation', 36),\n ('massacre', 36),\n ('nuclear reactor', 36),\n ('screaming', 36),\n ('tragedy', 36),\n ('accident', 35),\n ('airplane accident', 35),\n ('attacked', 35),\n ('bleeding', 35),\n ('blood', 35),\n ('bloody', 35),\n ('bridge collapse', 35),\n ('casualties', 35),\n ('collapsed', 35),\n ('demolition', 35),\n ('derail', 35),\n ('disaster', 35),\n ('drought', 35),\n ('emergency plan', 35),\n ('flood', 35),\n ('hail', 35),\n ('injured', 35),\n ('injury', 35),\n ('inundated', 35),\n ('razed', 35),\n ('rescued', 35),\n ('rescuers', 35),\n ('rioting', 35),\n ('screams', 35),\n ('storm', 35),\n ('structural failure', 35),\n ('suicide bomb', 35),\n ('tornado', 35),\n ('traumatised', 35),\n ('aftershock', 34),\n ('annihilated', 34),\n ('army', 34),\n ('arsonist', 34),\n ('blazing', 34),\n ('bomb', 34),\n ('burning', 34),\n ('burning buildings', 34),\n ('casualty', 34),\n ('collapse', 34),\n ('collide', 34),\n ('crashed', 34),\n ('demolish', 34),\n ('destruction', 34),\n ('drowning', 34),\n ('electrocuted', 34),\n ('flattened', 34),\n ('hazard', 34),\n ('heat wave', 34),\n ('lava', 34),\n ('loud bang', 34),\n ('military', 34),\n ('natural disaster', 34),\n ('nuclear disaster', 34),\n ('quarantine', 34),\n ('rainstorm', 34),\n ('refugees', 34),\n ('riot', 34),\n ('screamed', 34),\n ('smoke', 34),\n ('tsunami', 34),\n ('blew up', 33),\n ('blown up', 33),\n ('body bag', 33),\n ('body bagging', 33),\n ('buildings on fire', 33),\n ('burned', 33),\n ('chemical emergency', 33),\n ('crash', 33),\n ('emergency services', 33),\n ('exploded', 33),\n ('fire truck', 33),\n ('floods', 33),\n ('hijack', 33),\n ('hijacker', 33),\n ('injuries', 33),\n ('landslide', 33),\n ('lightning', 33),\n ('mass murder', 33),\n ('meltdown', 33),\n ('panicking', 33),\n ('stretcher', 33),\n ('suicide bombing', 33),\n ('survived', 33),\n ('thunderstorm', 33),\n ('trouble', 33),\n ('violent storm', 33),\n ('wildfire', 33),\n ('wounds', 33),\n ('apocalypse', 32),\n ('arson', 32),\n ('blight', 32),\n ('buildings burning', 32),\n ('cyclone', 32),\n ('destroyed', 32),\n ('detonation', 32),\n ('displaced', 32),\n ('drown', 32),\n ('electrocute', 32),\n ('eyewitness', 32),\n ('forest fires', 32),\n ('hailstorm', 32),\n ('hijacking', 32),\n ('mass murderer', 32),\n ('survive', 32),\n ('terrorism', 32),\n ('trapped', 32),\n ('crushed', 31),\n ('devastated', 31),\n ('hostage', 31),\n ('obliterate', 31),\n ('obliterated', 31),\n ('suicide bomber', 31),\n ('terrorist', 31),\n ('trauma', 31),\n ('wild fires', 31),\n ('avalanche', 30),\n ('catastrophic', 30),\n ('dead', 30),\n ('engulfed', 30),\n ('hazardous', 30),\n ('mayhem', 30),\n ('survivors', 30),\n ('annihilation', 29),\n ('bombing', 29),\n ('desolate', 29),\n ('first responders', 29),\n ('obliteration', 29),\n ('seismic', 29),\n ('sirens', 29),\n ('snowstorm', 29),\n ('demolished', 28),\n ('rubble', 28),\n ('deluged', 27),\n ('volcano', 27),\n ('battle', 26),\n ('bioterrorism', 26),\n ('bush fires', 25),\n ('hellfire', 25),\n ('war zone', 24),\n ('rescue', 22),\n ('forest fire', 19),\n ('epicentre', 12),\n ('threat', 11),\n ('inundation', 10),\n ('radiation emergency', 9)]"},"metadata":{}}]},{"cell_type":"markdown","source":"See much better now","metadata":{}},{"cell_type":"code","source":"test_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:18:48.531703Z","iopub.execute_input":"2021-09-06T11:18:48.532262Z","iopub.status.idle":"2021-09-06T11:18:48.541045Z","shell.execute_reply.started":"2021-09-06T11:18:48.532210Z","shell.execute_reply":"2021-09-06T11:18:48.540303Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"id         0\nkeyword    0\ntext       0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"All squeaky Clean too.\nLets append keyword to our tweets.","metadata":{}},{"cell_type":"code","source":"train_data['text'] = train_data['text'] + ' ' +  train_data['keyword']\ntest_data['text'] = test_data['text'] + ' ' +  test_data['keyword']","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:19:09.148563Z","iopub.execute_input":"2021-09-06T11:19:09.149155Z","iopub.status.idle":"2021-09-06T11:19:09.162890Z","shell.execute_reply.started":"2021-09-06T11:19:09.149101Z","shell.execute_reply":"2021-09-06T11:19:09.161977Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"There are still many cleaning of tweets that needs to be done. The \"#\" and \"@\" in the data. \nYou can try to clean that but I think the word piece tokenizer will take of rest of the scenario, you can try cleaning it it may improve the accuracy.","metadata":{}},{"cell_type":"markdown","source":"Lets split the data for training and validation split","metadata":{}},{"cell_type":"markdown","source":"# Tweet Cleaning\nShoutout to this guy !! what a intensive cleaning exercise man !!\nI took tweet cleaner from any existing notebook - https://www.kaggle.com/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert","metadata":{}},{"cell_type":"code","source":"def clean(tweet): \n            \n    # Special characters\n    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n    tweet = re.sub(r\"å_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n    tweet = re.sub(r\"åÊ\", \"\", tweet)\n    tweet = re.sub(r\"åÈ\", \"\", tweet)\n    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n    tweet = re.sub(r\"å¨\", \"\", tweet)\n    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n    tweet = re.sub(r\"åÇ\", \"\", tweet)\n    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n    tweet = re.sub(r\"åÀ\", \"\", tweet)\n    \n    # Contractions\n    tweet = re.sub(r\"he's\", \"he is\", tweet)\n    tweet = re.sub(r\"there's\", \"there is\", tweet)\n    tweet = re.sub(r\"We're\", \"We are\", tweet)\n    tweet = re.sub(r\"That's\", \"That is\", tweet)\n    tweet = re.sub(r\"won't\", \"will not\", tweet)\n    tweet = re.sub(r\"they're\", \"they are\", tweet)\n    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"What's\", \"What is\", tweet)\n    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n    tweet = re.sub(r\"There's\", \"There is\", tweet)\n    tweet = re.sub(r\"He's\", \"He is\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"You're\", \"You are\", tweet)\n    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n    tweet = re.sub(r\"you've\", \"you have\", tweet)\n    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n    tweet = re.sub(r\"we're\", \"we are\", tweet)\n    tweet = re.sub(r\"what's\", \"what is\", tweet)\n    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n    tweet = re.sub(r\"we've\", \"we have\", tweet)\n    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n    tweet = re.sub(r\"who's\", \"who is\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n    tweet = re.sub(r\"would've\", \"would have\", tweet)\n    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n    tweet = re.sub(r\"We've\", \"We have\", tweet)\n    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n    tweet = re.sub(r\"they've\", \"they have\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"should've\", \"should have\", tweet)\n    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n    tweet = re.sub(r\"where's\", \"where is\", tweet)\n    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n    tweet = re.sub(r\"They're\", \"They are\", tweet)\n    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n    tweet = re.sub(r\"let's\", \"let us\", tweet)\n    tweet = re.sub(r\"it's\", \"it is\", tweet)\n    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n    tweet = re.sub(r\"don't\", \"do not\", tweet)\n    tweet = re.sub(r\"you're\", \"you are\", tweet)\n    tweet = re.sub(r\"i've\", \"I have\", tweet)\n    tweet = re.sub(r\"that's\", \"that is\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n    tweet = re.sub(r\"I've\", \"I have\", tweet)\n    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n            \n    # Character entity references\n    tweet = re.sub(r\"&gt;\", \">\", tweet)\n    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n    \n    # Typos, slang and informal abbreviations\n    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n    tweet = re.sub(r\"w/\", \"with\", tweet)\n    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n    tweet = re.sub(r\"<3\", \"love\", tweet)\n    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n    \n    # Hashtags and usernames\n    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n    tweet = re.sub(r\"Newss\", \"News\", tweet)\n    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n    tweet = re.sub(r\"andword\", \"and word\", tweet)\n    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n    tweet = re.sub(r\"evng\", \"evening\", tweet)\n    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n           \n    # Urls\n    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n        \n    # Words with punctuations and special characters\n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n    for p in punctuations:\n        tweet = tweet.replace(p, f' {p} ')\n        \n    # ... and ..\n    tweet = tweet.replace('...', ' ... ')\n    if '...' not in tweet:\n        tweet = tweet.replace('..', ' ... ')      \n        \n    # Acronyms\n    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n    \n    # Grouping same words without embeddings\n    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n    \n    return tweet","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:19:42.800140Z","iopub.execute_input":"2021-09-06T11:19:42.800584Z","iopub.status.idle":"2021-09-06T11:19:43.030533Z","shell.execute_reply.started":"2021-09-06T11:19:42.800546Z","shell.execute_reply":"2021-09-06T11:19:43.029408Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\ntrain_data['text'] = train_data['text'].progress_apply(lambda s : clean(s))\ntqdm.pandas()\ntest_data['text'] = test_data['text'].progress_apply(lambda s : clean(s))","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:20:24.579788Z","iopub.execute_input":"2021-09-06T11:20:24.580411Z","iopub.status.idle":"2021-09-06T11:28:08.495279Z","shell.execute_reply.started":"2021-09-06T11:20:24.580306Z","shell.execute_reply":"2021-09-06T11:28:08.494093Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"100%|██████████| 7558/7558 [05:23<00:00, 23.33it/s]\n100%|██████████| 3263/3263 [02:19<00:00, 23.32it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"No more **plagiarism** . :P . Lets split the data","metadata":{}},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(train_data['text'].tolist(), train_data['target'].tolist())","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:28:49.853922Z","iopub.execute_input":"2021-09-06T11:28:49.854308Z","iopub.status.idle":"2021-09-06T11:28:49.872217Z","shell.execute_reply.started":"2021-09-06T11:28:49.854275Z","shell.execute_reply":"2021-09-06T11:28:49.870930Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained('roberta-large-mnli')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:28:53.155840Z","iopub.execute_input":"2021-09-06T11:28:53.156236Z","iopub.status.idle":"2021-09-06T11:28:55.873119Z","shell.execute_reply.started":"2021-09-06T11:28:53.156203Z","shell.execute_reply":"2021-09-06T11:28:55.872068Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/688 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51d59e67213d4570b7f22d2e7b165210"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e9192be5bcf4fa7b4c03b40c0210747"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13f52761783f494c9d692ddb79491d92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e8f23b765a44aec87b7aed429a86dc7"}},"metadata":{}}]},{"cell_type":"code","source":"training_encodings = tokenizer(train_texts,  padding=\"max_length\", truncation=True, return_tensors='tf')\nval_encodings = tokenizer(val_texts,  padding=\"max_length\", truncation=True, return_tensors='tf')","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:29:02.181816Z","iopub.execute_input":"2021-09-06T11:29:02.182206Z","iopub.status.idle":"2021-09-06T11:29:04.248686Z","shell.execute_reply.started":"2021-09-06T11:29:02.182174Z","shell.execute_reply":"2021-09-06T11:29:04.247743Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"Lets convert it data generator to that we can give this as an input to our model in batches.","metadata":{}},{"cell_type":"code","source":"train_tf_dataset = tf.data.Dataset.from_tensor_slices((dict(training_encodings), train_labels))\ntrain_tf_dataset = train_tf_dataset.shuffle(len(training_encodings)).batch(BATCH_SIZE)\n\neval_tf_dataset = tf.data.Dataset.from_tensor_slices((dict(val_encodings), val_labels))\neval_tf_dataset = eval_tf_dataset.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:29:12.535762Z","iopub.execute_input":"2021-09-06T11:29:12.536150Z","iopub.status.idle":"2021-09-06T11:29:12.578776Z","shell.execute_reply.started":"2021-09-06T11:29:12.536117Z","shell.execute_reply":"2021-09-06T11:29:12.577949Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# Lets define our model\nModel trained with SemEval 2017 corpus (around ~40k tweets). Base model is BerTweet, a RoBERTa model trained on English tweets.\nhttps://huggingface.co/finiteautomata/bertweet-base-sentiment-analysis\n\nWe are going to remove the last layer and append softmax dense layer for our output.","metadata":{}},{"cell_type":"code","source":"MAXLEN = training_encodings['input_ids'].shape[1]\n\nwith strategy.scope():\n    input_ids = tf.keras.Input(shape =(MAXLEN,), dtype=tf.int32, name='input_ids') \n    attention_mask = tf.keras.Input(shape=(MAXLEN,),dtype=tf.int32, name='attention_mask')  \n    \n    tf_model = TFAutoModel.from_pretrained('roberta-large-mnli', from_pt=True)\n    tf_model_output = tf_model([input_ids, attention_mask])[0]\n    \n    tf_model_output = tf.keras.layers.GlobalAveragePooling1D()(tf_model_output)\n    output = tf.keras.layers.Dense(2, activation = 'softmax')(tf_model_output)\n\n    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n\n    model.compile(optimizer = tf.keras.optimizers.Adam(lr=5e-6), \n                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n                      metrics=['accuracy'])     \n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:29:16.620980Z","iopub.execute_input":"2021-09-06T11:29:16.621389Z","iopub.status.idle":"2021-09-06T11:31:03.295145Z","shell.execute_reply.started":"2021-09-06T11:29:16.621356Z","shell.execute_reply":"2021-09-06T11:31:03.294056Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.43G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de7559d83094f95a5959dd939346135"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFRobertaModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_ids (InputLayer)          [(None, 512)]        0                                            \n__________________________________________________________________________________________________\nattention_mask (InputLayer)     [(None, 512)]        0                                            \n__________________________________________________________________________________________________\ntf_roberta_model (TFRobertaMode TFBaseModelOutputWit 355359744   input_ids[0][0]                  \n                                                                 attention_mask[0][0]             \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 1024)         0           tf_roberta_model[0][0]           \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 2)            2050        global_average_pooling1d[0][0]   \n==================================================================================================\nTotal params: 355,361,794\nTrainable params: 355,361,794\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I am only creating a early stoppping callbacks with patience =2. You can have multi callbacks like saving the checkpoints file along the training.","metadata":{}},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:31:11.606201Z","iopub.execute_input":"2021-09-06T11:31:11.606627Z","iopub.status.idle":"2021-09-06T11:31:11.611786Z","shell.execute_reply.started":"2021-09-06T11:31:11.606580Z","shell.execute_reply":"2021-09-06T11:31:11.610624Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"Lets start the training. Make sure BERT is a huge model it will quickly overfit your dataset.","metadata":{}},{"cell_type":"code","source":"model.fit(train_tf_dataset, \n        validation_data=eval_tf_dataset,\n        callbacks = [early_stop],\n        epochs=25,\n        verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:31:16.401195Z","iopub.execute_input":"2021-09-06T11:31:16.401579Z","iopub.status.idle":"2021-09-06T11:38:46.321989Z","shell.execute_reply.started":"2021-09-06T11:31:16.401545Z","shell.execute_reply":"2021-09-06T11:38:46.320978Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/25\n45/45 [==============================] - 305s 4s/step - loss: 0.6866 - accuracy: 0.5961 - val_loss: 0.4395 - val_accuracy: 0.8101\nEpoch 2/25\n45/45 [==============================] - 40s 892ms/step - loss: 0.4057 - accuracy: 0.8267 - val_loss: 0.3838 - val_accuracy: 0.8429\nEpoch 3/25\n45/45 [==============================] - 40s 891ms/step - loss: 0.3429 - accuracy: 0.8556 - val_loss: 0.3916 - val_accuracy: 0.8460\nEpoch 4/25\n45/45 [==============================] - 40s 889ms/step - loss: 0.3010 - accuracy: 0.8839 - val_loss: 0.4019 - val_accuracy: 0.8497\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f5f2c53b990>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lets do the prediction of the model on the testing data","metadata":{}},{"cell_type":"code","source":"test_encoded = tokenizer(test_data['text'].tolist(), padding='max_length', truncation=True, return_tensors='tf')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:40:24.022053Z","iopub.execute_input":"2021-09-06T11:40:24.022458Z","iopub.status.idle":"2021-09-06T11:40:24.540726Z","shell.execute_reply.started":"2021-09-06T11:40:24.022425Z","shell.execute_reply":"2021-09-06T11:40:24.539678Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Lets check the size of testing_data","metadata":{}},{"cell_type":"markdown","source":"Size is still big but we are dealing with TPU hence it is ok to take the whole data for inference. i will suggest you all to use batch prediction with batch generator when using GPU or CPU for low ram consumption.","metadata":{}},{"cell_type":"code","source":"output_predict = model.predict(test_encoded.data, batch_size=BATCH_SIZE, verbose =1)\npredictions = [np.argmax(i) for i in output_predict]","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:40:29.651538Z","iopub.execute_input":"2021-09-06T11:40:29.651923Z","iopub.status.idle":"2021-09-06T11:41:03.977021Z","shell.execute_reply.started":"2021-09-06T11:40:29.651892Z","shell.execute_reply":"2021-09-06T11:41:03.975958Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"26/26 [==============================] - 34s 1s/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Lets look into the sample that needs to be created","metadata":{}},{"cell_type":"code","source":"sample_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:41:07.387728Z","iopub.execute_input":"2021-09-06T11:41:07.388127Z","iopub.status.idle":"2021-09-06T11:41:07.399646Z","shell.execute_reply.started":"2021-09-06T11:41:07.388090Z","shell.execute_reply":"2021-09-06T11:41:07.398561Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       0\n1   2       0\n2   3       0\n3   9       0\n4  11       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Lets convert our prediction into that sample ","metadata":{}},{"cell_type":"code","source":"submission = test_data.id.copy().to_frame()\nsubmission['target'] = predictions\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:41:12.497323Z","iopub.execute_input":"2021-09-06T11:41:12.497734Z","iopub.status.idle":"2021-09-06T11:41:12.513592Z","shell.execute_reply.started":"2021-09-06T11:41:12.497700Z","shell.execute_reply":"2021-09-06T11:41:12.512148Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"   id  target\n0   0       1\n1   2       1\n2   3       1\n3   9       1\n4  11       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Finally !!  Submission Time !!","metadata":{}},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T11:41:17.892980Z","iopub.execute_input":"2021-09-06T11:41:17.893480Z","iopub.status.idle":"2021-09-06T11:41:17.910043Z","shell.execute_reply.started":"2021-09-06T11:41:17.893435Z","shell.execute_reply":"2021-09-06T11:41:17.908860Z"},"trusted":true},"execution_count":50,"outputs":[]}]}